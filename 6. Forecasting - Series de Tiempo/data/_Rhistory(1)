setwd("E:/Programa de Especialización - Data Science - Anthony Manosalva/R_Python/Módulo_V_Clasificación_Arboles_CHAID_y_CART")
library("readxl")
library("ggplot2")
library(gee)
library(readxl)
library(leaps)
library(dplyr)
library(caret)
library(pROC)
library(party)
library(C50)
library(rpart)
install.packages("readxl", dependencies = T)
install.packages("ggplot2", dependencies = T)
install.packages("gee", dependencies = T)
install.packages("ggplot2", dependencies = T)
library("readxl")
library("ggplot2")
library(gee)
library(readxl)
library(leaps)
library(dplyr)
library(caret)
library(pROC)
library(party)
library(C50)
library(rpart)
library("ggplot2")
install.packages("rlang", dependencies = T)
install.packages("rlang", dependencies = T)
library("ggplot2")
install.packages("ggplot2", dependencies = T)
library("ggplot2")
library(gee)
library(readxl)
library(leaps)
install.packages("leaps", dependencies = T)
library(leaps)
library(caret)
library(pROC)
library(party)
library(C50)
library(rpart)
Train=read.csv("data_loan_status_limpia.csv")
sample_n(Train, 3)
#### -- 1) Librerias a usar ####
library("readxl")
library("ggplot2")
library(gee)
library(readxl)
library(leaps)
library(dplyr)
library(caret)
library(pROC)
library(party)
library(C50)
library(rpart)
sample_n(Train, 3)
sample_n(Train, 3)
cor(Train[,1:8])
library(corrplot)
install.packages("corrplot", dependencies = T)
library(corrplot)
corrplot(cor(Train[,1:8]))
set.seed(123)
training.samples <- Train$Loan_Status %>%
createDataPartition(p = 0.8, list = FALSE)
train.data  <- Train[training.samples, ]
test.data <- Train[-training.samples, ]
# modelo 1.- Arbol CHAID
#El árbol viene de la librería party
modelo1<-ctree(Loan_Status~.,data = train.data,
controls=ctree_control(mincriterion=0.95))
##probabilidades
proba1=sapply(predict(modelo1, newdata=test.data,type="prob"),'[[',1)
##probabilidades
proba1=sapply(predict(modelo1, newdata=test.data,type="prob"),'[[',1)
# curva ROC
AUC1 <- roc(test.data$Loan_Status, proba1)
auc_modelo1=AUC1$auc
# Gini
gini1 <- 2*(AUC1$auc) -1
# Calcular los valores predichos
PRED <-ifelse(proba1 <= 0.5 ,0,1)
# Calcular la matriz de confusi?n
tabla=confusionMatrix(PRED,test.data$Loan_Status,positive = "1")
# sensibilidad
Sensitivity1=as.numeric(tabla$byClass[1])
# Precision
Accuracy1=tabla$overall[1]
# Calcular el error de mala clasificaci?n
error1=mean(PRED!=test.data$Loan_Status)
# indicadores
auc_modelo1
gini1
Accuracy1
error1
Sensitivity1
tabla
arbol.completo <- rpart(Loan_Status~.,data = train.data,method="class",cp=0, minbucket=0)
xerr <- arbol.completo$cptable[,"xerror"] ## error de la validacion cruzada
minxerr <- which.min(xerr)
mincp <- arbol.completo$cptable[minxerr, "CP"]
modelo2 <- prune(arbol.completo,cp=mincp)
plot(arbol.completo)
modelo2 <- prune(arbol.completo,cp=mincp)
plot(modelo2)
##probabilidades
proba2=predict(modelo2, newdata=test.data,type="prob")[,2]
# curva ROC
AUC2 <- roc(test.data$Loan_Status, proba2)
auc_modelo2=AUC2$auc
# Gini
gini2 <- 2*(AUC2$auc) -1
# Calcular los valores predichos
PRED <-predict(modelo2, newdata=test.data,type="class")
# Calcular la matriz de confusi?n
tabla=confusionMatrix(PRED,test.data$Loan_Status,positive = "1")
# sensibilidad
Sensitivity2=as.numeric(tabla$byClass[1])
# Precision
Accuracy2=tabla$overall[1]
# Calcular el error de mala clasificaci?n
error2=mean(PRED!=test.data$Loan_Status)
# indicadores
auc_modelo2
gini2
Accuracy2
error2
Sensitivity2
train.data$Loan_Status= as.factor(train.data$Loan_Status)
rm(list=ls())
##########################################################################
##### -- Programa de EspecializaciÃ³n en Data Science - Nivel I -- #######
##########################################################################
######## Tema : Arboles de Decision #######################################
######## Autores: Jose Cardenas - Andre Chavez  ##########################
##########################################################################
#### -- 1) Librerias a usar ####
library("readxl")
library("ggplot2")
library(gee)
library(readxl)
library(leaps)
library(dplyr)
library(caret)
library(pROC)
library(party)
library(C50)
library(rpart)
library(corrplot)
install.packages("corrplot", dependencies = T)
#### -- 2) Modelo de Arboles de Decision
## Cargar la data
Train=read.csv("data_loan_status_limpia.csv")
## Observar aleatoriamente 3 valores de la data
sample_n(Train, 3)
## supuestos
corrplot(cor(Train[,1:8]))
## Particion Muestral
set.seed(123)
training.samples <- Train$Loan_Status %>%
createDataPartition(p = 0.8, list = FALSE)
train.data  <- Train[training.samples, ]
test.data <- Train[-training.samples, ]
## Modelos de Arboles
# modelo 1.- Arbol CHAID
#El árbol viene de la librería party
modelo1<-ctree(Loan_Status~.,data = train.data,
controls=ctree_control(mincriterion=0.95))
##probabilidades
proba1=sapply(predict(modelo1, newdata=test.data,type="prob"),'[[',1)
# curva ROC
AUC1 <- roc(test.data$Loan_Status, proba1)
auc_modelo1=AUC1$auc
# Gini
gini1 <- 2*(AUC1$auc) -1
# Calcular los valores predichos
PRED <-ifelse(proba1 <= 0.5 ,0,1)
# Calcular la matriz de confusión
tabla=confusionMatrix(PRED,test.data$Loan_Status,positive = "1")
# sensibilidad
Sensitivity1=as.numeric(tabla$byClass[1])
# Precision
Accuracy1=tabla$overall[1]
# Calcular el error de mala clasificaci?n
error1=mean(PRED!=test.data$Loan_Status)
# indicadores
auc_modelo1
gini1
Accuracy1
error1
Sensitivity1
# modelo 2.- Arbol CART
arbol.completo <- rpart(Loan_Status~.,data = train.data,method="class",cp=0, minbucket=0)
xerr <- arbol.completo$cptable[,"xerror"] ## error de la validacion cruzada
minxerr <- which.min(xerr)
mincp <- arbol.completo$cptable[minxerr, "CP"]
#CP índice de pureza
plot(arbol.completo)
modelo2 <- prune(arbol.completo,cp=mincp)
plot(modelo2)
##probabilidades
proba2=predict(modelo2, newdata=test.data,type="prob")[,2]
# curva ROC
AUC2 <- roc(test.data$Loan_Status, proba2)
auc_modelo2=AUC2$auc
# Gini
gini2 <- 2*(AUC2$auc) -1
# Calcular los valores predichos
PRED <-predict(modelo2, newdata=test.data,type="class")
# Calcular la matriz de confusi?n
tabla=confusionMatrix(PRED,test.data$Loan_Status,positive = "1")
# sensibilidad
Sensitivity2=as.numeric(tabla$byClass[1])
# Precision
Accuracy2=tabla$overall[1]
# Calcular el error de mala clasificaci?n
error2=mean(PRED!=test.data$Loan_Status)
# indicadores
auc_modelo2
gini2
Accuracy2
error2
Sensitivity2
# modelo 3.- Arbol c5.0
#Para este algoritmo el target tiene que ser CATEGÓRICO (factor)
#--> Supuesto: Y debe ser factor
train.data$Loan_Status= as.factor(train.data$Loan_Status)
modelo3 <- C5.0(Loan_Status~.,data = train.data,trials = 55,rules= TRUE,tree=FALSE,winnow=FALSE)
##probabilidades
proba3=predict(modelo3, newdata=test.data,type="prob")[,2]
# curva ROC
AUC3 <- roc(test.data$Loan_Status, proba3)
auc_modelo3=AUC3$auc
# Gini
gini3 <- 2*(AUC3$auc) -1
# Calcular los valores predichos
PRED <-predict(modelo3, newdata=test.data,type="class")
# Calcular la matriz de confusi?n
tabla=confusionMatrix(PRED,test.data$Loan_Status,positive = "1")
# sensibilidad
Sensitivity3=as.numeric(tabla$byClass[1])
# Precision
Accuracy3=tabla$overall[1]
# Calcular el error de mala clasificaci?n
error3=mean(PRED!=test.data$Loan_Status)
# indicadores
auc_modelo3
gini3
Accuracy3
error3
Sensitivity3
## --Tabla De Resultados ####
AUC=rbind(auc_modelo1,
auc_modelo2,
auc_modelo3
)
GINI=rbind(gini1,
gini2,
gini3
)
Accuracy=rbind(Accuracy1,
Accuracy2,
Accuracy3
)
ERROR= rbind(error1,
error2,
error3
)
SENSIBILIDAD=rbind(Sensitivity1,
Sensitivity2,
Sensitivity3
)
resultado=data.frame(AUC,GINI,Accuracy,ERROR,SENSIBILIDAD)
rownames(resultado)=c('CHAID',
'CART',
'C50'
)
resultado=round(resultado,2)
resultado
## Resultado Ordenado #####
# ordenamos por el Indicador que deseamos, quiza Accuracy en forma decreciente
Resultado_ordenado <- resultado[order(-Accuracy),]
Resultado_ordenado
install.packages("corrplot", dependencies = T)
rm(list=ls())
##########################################################################
##### -- Programa de EspecializaciÃ³n en Data Science - Nivel I -- #######
##########################################################################
######## Tema : Arboles de Decision #######################################
######## Autores: Jose Cardenas - Andre Chavez  ##########################
##########################################################################
#### -- 1) Librerias a usar ####
library("readxl")
library("ggplot2")
library(gee)
library(readxl)
library(leaps)
library(dplyr)
library(caret)
library(pROC)
library(party)
library(C50)
library(rpart)
library(corrplot)
#install.packages("corrplot", dependencies = T)
#### -- 2) Modelo de Arboles de Decision
## Cargar la data
Train=read.csv("data_loan_status_limpia.csv")
## Observar aleatoriamente 3 valores de la data
sample_n(Train, 3)
## supuestos
corrplot(cor(Train[,1:8]))
## Particion Muestral
set.seed(123)
training.samples <- Train$Loan_Status %>%
createDataPartition(p = 0.8, list = FALSE)
train.data  <- Train[training.samples, ]
test.data <- Train[-training.samples, ]
## Modelos de Arboles
# modelo 1.- Arbol CHAID
#El árbol viene de la librería party
modelo1<-ctree(Loan_Status~.,data = train.data,
controls=ctree_control(mincriterion=0.95))
##probabilidades
proba1=sapply(predict(modelo1, newdata=test.data,type="prob"),'[[',1)
# curva ROC
AUC1 <- roc(test.data$Loan_Status, proba1)
auc_modelo1=AUC1$auc
# Gini
gini1 <- 2*(AUC1$auc) -1
# Calcular los valores predichos
PRED <-ifelse(proba1 <= 0.5 ,0,1)
# Calcular la matriz de confusión
tabla=confusionMatrix(PRED,test.data$Loan_Status,positive = "1")
# sensibilidad
Sensitivity1=as.numeric(tabla$byClass[1])
# Precision
Accuracy1=tabla$overall[1]
# Calcular el error de mala clasificaci?n
error1=mean(PRED!=test.data$Loan_Status)
# indicadores
auc_modelo1
gini1
Accuracy1
error1
Sensitivity1
# modelo 2.- Arbol CART
arbol.completo <- rpart(Loan_Status~.,data = train.data,method="class",cp=0, minbucket=0)
xerr <- arbol.completo$cptable[,"xerror"] ## error de la validacion cruzada
minxerr <- which.min(xerr)
mincp <- arbol.completo$cptable[minxerr, "CP"]
#CP índice de pureza
plot(arbol.completo)
modelo2 <- prune(arbol.completo,cp=mincp)
plot(modelo2)
##probabilidades
proba2=predict(modelo2, newdata=test.data,type="prob")[,2]
# curva ROC
AUC2 <- roc(test.data$Loan_Status, proba2)
auc_modelo2=AUC2$auc
# Gini
gini2 <- 2*(AUC2$auc) -1
# Calcular los valores predichos
PRED <-predict(modelo2, newdata=test.data,type="class")
# Calcular la matriz de confusi?n
tabla=confusionMatrix(PRED,test.data$Loan_Status,positive = "1")
# sensibilidad
Sensitivity2=as.numeric(tabla$byClass[1])
# Precision
Accuracy2=tabla$overall[1]
# Calcular el error de mala clasificaci?n
error2=mean(PRED!=test.data$Loan_Status)
# indicadores
auc_modelo2
gini2
Accuracy2
error2
Sensitivity2
# modelo 3.- Arbol c5.0
#Para este algoritmo el target tiene que ser CATEGÓRICO (factor)
#--> Supuesto: Y debe ser factor
train.data$Loan_Status= as.factor(train.data$Loan_Status)
modelo3 <- C5.0(Loan_Status~.,data = train.data,trials = 55,rules= TRUE,tree=FALSE,winnow=FALSE)
##probabilidades
proba3=predict(modelo3, newdata=test.data,type="prob")[,2]
# curva ROC
AUC3 <- roc(test.data$Loan_Status, proba3)
auc_modelo3=AUC3$auc
# Gini
gini3 <- 2*(AUC3$auc) -1
# Calcular los valores predichos
PRED <-predict(modelo3, newdata=test.data,type="class")
# Calcular la matriz de confusi?n
tabla=confusionMatrix(PRED,test.data$Loan_Status,positive = "1")
# sensibilidad
Sensitivity3=as.numeric(tabla$byClass[1])
# Precision
Accuracy3=tabla$overall[1]
# Calcular el error de mala clasificaci?n
error3=mean(PRED!=test.data$Loan_Status)
# indicadores
auc_modelo3
gini3
Accuracy3
error3
Sensitivity3
## --Tabla De Resultados ####
AUC=rbind(auc_modelo1,
auc_modelo2,
auc_modelo3
)
GINI=rbind(gini1,
gini2,
gini3
)
Accuracy=rbind(Accuracy1,
Accuracy2,
Accuracy3
)
ERROR= rbind(error1,
error2,
error3
)
SENSIBILIDAD=rbind(Sensitivity1,
Sensitivity2,
Sensitivity3
)
resultado=data.frame(AUC,GINI,Accuracy,ERROR,SENSIBILIDAD)
rownames(resultado)=c('CHAID',
'CART',
'C50'
)
resultado=round(resultado,2)
resultado
## Resultado Ordenado #####
# ordenamos por el Indicador que deseamos, quiza Accuracy en forma decreciente
Resultado_ordenado <- resultado[order(-Accuracy),]
Resultado_ordenado
C5.0?
""
1"#"
?C5.0
setwd("E:/Programa de Especialización - Data Science - Anthony Manosalva/R_Python/Módulo VI _ Pronóstico - Series de Tiempo/DataSet")
gas = scan('http://www.uam.es/joser.berrendero/datos/gas6677.dat')
#install.packages("ggplot2")
library(ggplot2)
#install.packages("TSA")
library(TSA)
#install.packages("forecast")
library(forecast)
library(scales)
library(stats)
#library(arima)
install.packages("TSA", dependencies = T)
install.packages("forecast", dependencies = T)
#install.packages("ggplot2")
library(ggplot2)
#install.packages("TSA")
library(TSA)
#install.packages("forecast")
library(forecast)
library(scales)
library(stats)
#library(arima)
#install.packages("ggplot2")
library(ggplot2)
#install.packages("TSA")
library(TSA)
#install.packages("forecast")
library(forecast)
library(scales)
library(stats)
#library(arima)
# Carga de datos
Yt<-read.delim("datatesisaereo.txt",header=T)
Yt
Yt<-ts(Yt,start=c(2000,1),freq=12)
# Carga de datos
Yt<-read.delim("datatesisaereo.txt",header=T)
Yt
#Le decimos a R que vamos a trabajar con series de tiempo
Yt<-ts(Yt,start=c(2000,1),freq=12)
#En caso de querer trabajarlo como dataframe, más que nada para la parte visual.
date<-seq(as.Date("2000/01/01"),as.Date("2012/12/01"),by="months")
data<-data.frame(Yt,date)
plot(Yt)
print(Yt)
cycle(Yt)
boxplot(Yt ~ cycle(Yt))
#Veamos si existe o no estacionalidad, si la mediana está muy alta que todas las demás, entonces en ese mes puede ocurrir estacionalidad.
boxplot(Yt ~ cycle(Yt))
Yt_d = decompose(Yt)
plot(Yt_d, xlab='Año')
Yt_d
